# SALMON Testing Approach

The SALMON project implements several types of testing to ensure robust and reliable functionality:

- **Unit Tests**: Lightweight tests that focus on individual components, verifying that each module behaves as expected.
- **Integration Tests**: These tests ensure that the AWS services used by SALMON interact correctly and fulfill their intended purposes.
- **Deployment Tests**: These tests verify the correctness of the CDK (Cloud Development Kit) deployment.

Tests are automatically executed when merging into the `main` branch and on various other occasions. Running these tests on pull request merges ensures that the application functions correctly and that no breaking changes are introduced.

For contributors, it's recommended to run the tests before submitting a pull request. This section outlines how to configure, prepare, and execute tests, both through GitHub Actions workflows and in a local environment.

## Unit Tests

### Configuration and Prerequisites

1. Create a Python virtual environment (you can also reuse the one used for deployment).
2. Install the necessary dependencies from `requirements-test.txt`.

### Running Unit Tests

To run the unit tests, execute the following command:

```bash
pytest tests/
```

## Integration tests

### How Integration tests are designed

In order to execute integration tests, the separate isolated environment is spinned-up, which includes:
   1. **Standard SALMON resources**: These include both the `tooling` and `monitored` environments.
   2. **Test-specific resources**: Additional resources created specifically for integration tests:
      1. *Testing stand resources* (e.g. Glue Jobs) of each resource type handled by SALMON. Typically one resource per type that always fails (to test alerts and failure handling) and one that always succeeds.
      2. *Infrastructure to capture alerts and other messages* (e.g. digest) generated by SALMON upon events happening in testing stand resources. This includes a an SNS topic as a destination for all messages and DynamoDB table to persistently store them.
   3. **JSON configuration files**: These files orchestrate interaction between SALMON and testing resources. For instance, SNS topic referred to in `recipients.json` as the main destination, and monitoring groups are configured to reference the testing stand resources.

The default name for the environment is `devit`.

![Integration Tests Environment](/docs/images/inttests-infra.png "Integration Tests Environment")

The integration test process involves the following steps:

1. **Creation of AWS resources**: All resources, including SALMON resources and test-specific infrastructure, are provisioned.
2. **Testing stand execution**:
   1. All testing stand resources are triggered, and their execution is monitored until completion. This step generates the necessary alerts based on pre-configured resource failures.
   2. The `extract-metrics-orch` lambda function is executed to store metrics in a Timestream table.
   3. The Digest Lambda function is executed to generate a digest of the resource execution.
3. **Analysis of test results**: The analysis is performed in the form of pytest tests, focusing on two key areas:
   1. Tests common for all resource types (such as, "we didn't observe any internal SALMON failures", "digest message is generated succesfully").
   2. Tests specific for each resource type (including checking metrics values, expected alert messages arrivals etc.)
4. **Resource cleanup**: All AWS Resources created in step #1 are deleted.

![Integration Tests Workflow](/docs/images/inttests-steps.png "Integration Tests Workflow")

### Configuration and prerequisistes

1. **IAM Service Role for GitHub Actions**: An IAM Role is required for running tests via GitHub Actions. You can create it using the `github_actions_resources` CDK application:

   - Navigate to folder `cdk/github_actions_resources`
   - Run the command `cdk deploy` to create a CDK stack that includes IAM role, including permissions sufficient to run tests and trust relationships to allow your GitHub repo actions assume this role when executing workflows.
   - In your github repository, go to **Settings -> Secrets and Variables -> Action**, and add a secret named `AWS_ACCOUNT_ID` so GitHub knows which account to use for running pipelines.

2. **SALMON configuration files**: The configuration files for the integration tests environment are stored in `integration_tests/settings` folder.  
You can customize these files (changes need to be pushed to repository to take effect).

### Running integration tests via Github Workflows

To run the full integration tests workflow via GitHub, no additional preparation is necessary. Simply trigger the `Integration Tests - Full Workflow` action.

If you plan to execute the tests multiple times, follow these steps:

1. Run workflow `Integration Tests - Create Infra` workflow to provision all required AWS resources.
2. Once the infrastructure is set up, you can execute the tests by triggering the `Integration Tests - Execute Tests` workflow as many times as needed.
3. When finished, run the `Integration Tests - Delete Infra` workflow to clean up and remove the resources.

### Running integration tests on a local machine

Running integration tests locally offers additional flexibility, allowing you to decouple the execution of the testing stand from the analysis of test results. This can be particularly useful when debugging the pytest portion of the code.

1. Trigger the `Integration Tests - Create Infra` workflow to provision all necessary AWS resources. Make note of the stage name used during resource creation (the default is `devit`).
2. Once the infrastructure is in place, you can execute the scripts locally:

To trigger the testing stand execution, run the following command (replace the parameter values if needed):
```bash
  python integration_tests/testing_stand_execution.py --stage-name devit --region eu-central-1
```

You can include the optional `--resource-types` parameter with a comma-separated list of resource types to trigger execution of only the specified resource types. If this parameter is omitted or set to "all", all resource types will be executed.

The first output line of the script provides a start time (in epoch milliseconds). You will use this value later to filter artifacts during the pytest test result analysis.

To analyze test results (using pytest), run the following command, replacing the start-epochtimemsec parameter with the epoch time from the previous step:
```bash
  pytest integration_tests/tests --stage-name devit --region eu-central-1 --start-epochtimemsec 123456789000
```   
3. Once testing is complete, run the `Integration Tests - Delete Infra` workflow to tear down all resources.

## Deployment tests

### Configuration and prerequisistes

1. **IAM service user for GitHub Actions**: The CDK Deployment workflow uses the same IAM user as the Integration Tests. If youâ€™ve already created the user following the instructions in the `prerequisites` section of the Integration Tests, no further action is needed.
2. **SALMON configuration files**: The configuration files for the deployment tests environment are stored in the `tests/devcdk` folder.
You can customize these files, but any changes must be pushed to the repository to take effect.

### Running deployment tests

Deployment tests are executed by triggering the `CDK Deployment tests` GitHub workflow. The pipeline follows these steps:
1. Create the `tooling` environment resource (here and below the default stage-name is `devcdk`).
2. Create the `monitoring` environment
3. Delete the `monitoring` environment
4. Delete the `tooling` environment

This sequence ensure the main CDK flow is executed without errors.

